#### Learning to learn by gradient descent by gradient descent

#### Domain Separation Networks

#### On First-Order Meta-Learning Algorithms

#### Bilevel Programming for Hyperparameter Optimization and Meta-Learning

> 题目：Learning to learn by gradient descent by gradient descent
>
> 来源：NeurIPS 2016
>
> 作者：Google DeepMind

### 解决的问题：

Meta-learning中task的输入类似于RNN的序列输入，由此启发使用LSTM来学一个动态的学习率代替手工设计学习率，更新参数。

### idea

目前更新参数都是针对特定问题，手动设计规则更新参数，本文提出一个优化器，通过动态的学习一组参数，实现针对个性问题的不同学习率，在我看来，RNN也是一个NN，这个NN输入loss的梯度和上一阶段的学习率，输出下一阶段的学习率。

相关工作：使用RL训练一个步长的controller



<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210522102832262.png" alt="image-20210522102832262" style="zoom:67%;" />

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210522103322155.png" alt="image-20210522103322155" style="zoom:50%;" />

m函数输入loss的梯度和隐状态，输出step-size，忽略沿虚线边缘的梯度就等于假设优化对象的梯度不依赖于优化程序参数

使用全连接的RNN参数量过大，这里重复使用同一个RNN共享参数，计算量减少

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210522105044124.png" alt="image-20210522105044124" style="zoom: 50%;" />

1、网络将单个坐标的最佳梯度和先前的隐藏状态作为输入，并输出对应的最佳参数的更新

2、递归的使用使LSTM可以学习动态更新规则，该规则整合了与动量类似的来自梯度历史的信息

> 题目：Bilevel Programming for Hyperparameter Optimization and Meta-Learning
>
> 来源：PMLR 2018
>
> 作者：Luca Franceschi  Paolo Frasconi  Saverio Salzo Riccardo Grazzi  Massimiliano Pontil 



### 要解决的问题：

both HO and ML essentially **boil down to** nesting two search problems: at the inner level we seek a good hypothesis (as in standard supervised learning) while at the outer level we seek a good configuration (including a good hypothesis space) where the inner search takes place.

HO和ML基本上都归结为双层嵌套搜索问题：

在内部，我们寻找一个好的假设（如标准监督学习）

在外部，我们寻找一个好的配置（包括一个好的假设空间，在其中perform the inner search ）



HO：

在HO中，可用数据与单个任务相关联，并分成训练集（用于调整参数）和验证集（用于调整超参数）类似于NAS

在HO中，外部问题涉及超参数，而内部问题通常是经验损失的最小化。

ML：

在ML中，我们通常对所谓的“few-shot”学习设置感兴趣，其中数据以 short episodes的形式出现（小数据集，每个类只有很少的样本），是从监督任务的常见概率分布中采样的。

在ML中，外部问题可能涉及任务之间的共享表示，而内部问题可能涉及单个任务的分类器。





将神经网络最后一层的权值作为内变量，将表示映射参数化的剩余权值作为外变量。



<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210519205005654.png" alt="image-20210519205005654" style="zoom:50%;" />



> 题目：Domain Separation Networks
>
> 来源：NIPS 2016
>
> 作者：Google Brain

### 解决的问题：

域自适应或域泛化：解决同类目标在不同域的表示不一致，避免重复标注大规模数据及，当前的方法：

1、mapping：mapping representations from one domain to the other

2、 shared representation： learning to extract features that are invariant to the domain from which they were extracted.

不足：

1、只关注不同域的差别，但是 ignore the individual characteristics of each domain，

2、shared representation：使得共享表示容易受到与底层共享分布相关的噪声的污染

解决方案：introduces the notion of a private subspace for each domain

### idea:

“low-level” differences： noise, resolution, illumination and color. 

“High-level” differences：  the number of classes, the types of objects, and geometric variations, such as 3D position and pose. 



A private subspace：模型为每个域引入了一个私有子空间的概念，它捕获特定于域的属性，例如背景和低级图像统计。

A shared subspace：一个共享的子空间，通过使用自动编码器和显式损失函数，捕获域共享的表示。

通过找到一个与私有子空间**正交**的共享子空间，模型能够分离出每个域所特有的信息，并在此过程中产生对手头任务更有意义的表示。

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520151854646.png" alt="image-20210520151854646" style="zoom:67%;" />

The private component of the representation is specific to a single domain and the shared component of the representation is shared by both domains.

为了使模型产生这样的分裂表示，增加了一个损失函数来鼓励这些部分的独立性。

在共享表示上训练的分类器能够更好地跨域泛化，因为其输入不受每个域所特有的表示方面的污染。

### loss：

**$L_{recon}$：**

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520153424659.png" alt="image-20210520153424659" style="zoom:50%;" />

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520153440022.png" alt="image-20210520153440022" style="zoom:50%;" />

scale–invariant mean squared error term ：2范数+规整项，假如 $\hat{x}$和$x$只在整体像素少一个常数，规整项会弥补这个差距。

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520154139513.png" alt="image-20210520154139513" style="zoom:50%;" />

理解尺度不变均方误差，通过论文Depth Map Prediction from a Single Image using a Multi-Scale Deep Network：<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520155832250.png" alt="image-20210520155832250" style="zoom:50%;" />



这使模型能够学习重现要建模的对象的整体形状，而无需在输入的绝对颜色或亮度上花费建模能力

（This allows the model to learn to reproduce the overall shape of the objects being modeled without expending modeling power on the absolute color or intensity of the inputs. ）

**$L_{difference}$：**

差异损失鼓励了每个域的共享表示和私有表示之间的正交性：

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520161524577.png" alt="image-20210520161524577" style="zoom:50%;" />

使用余弦距离来度量 private and shared representation of each domain的距离，相关性越小损失越小，相互独立时为0

**$L_{similar}$：**

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210520170444294.png" alt="image-20210520170444294" style="zoom:50%;" />

### 改进方向：

1、we assume that they have high level parameters with similar distributions and the same label space.

而现实世界 label space 一般是不同的，而NN 改变了 label space 后需要重新训练，这是一个难题。

2、Gradient Reversal Layer (GRL) ：梯度方向是使得分类器更容易区分来自不同域样本，而梯度翻转确实让分类器更confuse，但是这个方向的选择是靠直觉选择的。

### 词句：

1、 circumventing this cost 规避这一成本

2、 vulnerable to contamination  易受污染

3、By partitioning the space in such a manner, the classifier trained on the shared representation is better able to generalize across domains as its inputs are uncontaminated with aspects of the representation that are unique to each domain.

通过以这种方式划分空间，在共享表示形式上训练的分类器可以更好地跨域进行泛化，因为其输入不受每个域唯一的表示形式的污染

4、 are partitioned into   .....分为....

5、Our novel architecture results in a model   我们新颖的架构形成了一个模型

6、 manipulate 

7、 Existing approaches focus either on mapping representations from one domain to the other, or on learning to extract features that **are invariant to** the domain from which they were extracted. 

现有方法侧重于将表示形式从一个域映射到另一域，或者着重于学习提取与提取它们的域不变的特征

> 题目：On First-Order Meta-Learning Algorithms
>
> 作者：Alex Nichol and Joshua Achiam and John Schulman OpenAI
>
> key：并不是找global minima对应的weight（pre-training），而是找对于task distribution里面random sample出来一个task，经过k步update，能得到global minima的initialization weight

### 解决的问题：

1、解决了MAML计算量太大的问题

2、first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification

### idea：

通过忽略二阶导数，得到对于MAML的一阶近似，同时Reptile doesn’t need a training-test split for each task

### detail：

因为经典的pre-training方法并不能保证学习一个有利于fine-tuning的初始化参数，所以MAML被提出来，

FOMAML是对MAML的简化 ：

计算细节：using a first-order approximation

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210518222919447.png" alt="image-20210518222919447" style="zoom:50%;" />

 <img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210518224035247.png" alt="image-20210518224035247" style="zoom: 33%;" />

结果就是：

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210518224315214.png" alt="image-20210518224315214" style="zoom:50%;" />

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210518224646508.png" alt="image-20210518224646508" style="zoom: 50%;" />

reptile：

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210519121345308.png" alt="image-20210519121345308" style="zoom:50%;" />

对比：

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210519121723601.png" alt="image-20210519121723601" style="zoom:50%;" />

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210519122217343.png" alt="image-20210519122217343" style="zoom:50%;" />

reptile看起来和pre-training很相似，Instead, the update includes important terms coming from second-and-higher derivatives of Lτ ,

数学推导：

1、

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210519150626078.png" alt="image-20210519150626078" style="zoom:67%;" />

2、we argue that Reptile converges towards a solution φ that is close (in Euclidean distance) to each task τ’s manifold of optimal solutions. 



### 词句

1、be explained as  被解释为   emulate  模仿

2、may be computationally intractable  可能在计算上很难

3、A variety of different approaches to meta-learning have been proposed, each with its own pros and cons.

人们提出了多种不同的元学习方法，每种方法都有各自的优缺点。

4、this classic pre-training approach has no guarantee of learning an initialization that is good for fine-tuning, and ad-hoc tricks **the  are required for** good performance. 这种经典的预训练方法不能保证学习一个有利于微调的初始化，而要获得良好的性能需要一些特殊的技巧。

5、 proposed an algorithm called MAML, which directly optimizes performance with respect to this initialization—differentiating through the fine-tuning process. 提出了一种称为MAML的算法，该算法通过微调过程直接优化与此初始化微分有关的性能

6、In this approach, the learner   **falls back on** a sensible gradient-based learning algorithm even when it receives out-of-sample data, **thus allowing it to** generalize **better than** the RNN-based approaches

在这种方法中，学习者即使在接收到样本外的数据时也会**依赖**一种基于梯度的学习算法，从而使其比基于RNN的方法具有更好的泛化能力