

## Attention Is All You Need、MAML、Meta-Learning  Survey、SNAS、P-DARTS、PROXYLESS-NAS





>    题目：Attention Is All You Need
>
> 来源： NIPS 2017
>
> 作者：Google Brain



### 解决的问题：

1、在序列转换任务中，RNN系列学习长程依赖关系比较困难，因为前后 signals 必须跨越整个路径长度才能建立联系：

在这些模型中，将两个任意输入或输出位置的信号关联起来所需的操作数随着位置之间的距离而增长，这使得学习长程依赖关系变得更加困难。transformer中，此操作被减少为恒定的操作次数，尽管由于平均注意力加权位置而导致有效分辨率降低，使用Multi-Head Attention可以抵消。

2、并行计算，大大缩短了计算时间



### detail：



Self-attention：将单个序列的不同位置联系起来，以计算序列的表示形式。

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210511202313397.png" alt="image-20210511202313397" style="zoom: 50%;" />

the output of each sub-layer ： $ LayerNorm(x + Sublayer(x)),$ 

Scaled Dot-Product Attention：The input consists of queries and keys of dimension $d_k$, and values of dimension $d_v$. 

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210511205233967.png" alt="image-20210511205233967" style="zoom:50%;" />

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210511205130560.png" alt="image-20210511205130560" style="zoom: 67%;" />



Multi-Head Attention：使用不同的线性投影将查询、键和值线性投影h次，分别投影到dk、dk和dv维，在查询、键和值的每个投影版本上，并行地执行注意函数，产生dv维的输出值。它们被连接起来并再次投影，从而得到最终值。

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210511225634121.png" alt="image-20210511225634121" style="zoom:50%;" />



Multi-Head Attention使得模型能够在不同的位置共同关注来自不同表示子空间的信息

![image-20210511225955265](/Users/lishuo/Library/Application Support/typora-user-images/image-20210511225955265.png)



The Transformer 以三种不同的方式使用 multi-head attention：

* Encoder-Decnoder Attention：当前翻译和编码的特征向量之间的关系

  Q来自于前面的decode层，K,V来自于encode的输出，这允许decode中的每个位置都参与输入序列中的所有位置

* Self-Attention：

  Encoder：编码器中的每个位置都可以参与到编码器前一层中的所有位置

  Decode：需要防止decode中的信息流向左流动，以保持自回归特性，通过屏蔽softmax输入中与非法连接相对应的所有值来实现scaled dot-product attention



### 改进方向：

重要的位置信息被额外的编码，必然带来信息的丢失

### 词句：

1、dispensing with 免除    be superior in 在...方面胜过

2、 This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples. 

这种固有的顺序性质阻止了训练示例内的并行化，这在较长的序列长度上变得至关重要，因为内存限制限制了示例之间的批处理。

3、Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences 

注意机制已成为各种任务中引人注目的序列建模和转导模型不可或缺的一部分，允许建模依赖关系，而不考虑它们在输入或输出序列中的距离。

4、albeit at 尽管在

5、The encoder is composed of a stack of N = 6 identical layers.编码器由N=6个相同层组成

6、 mimics 模仿

7、replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.



> 题目：Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
>
> 来源： ICML 2017
>
> 作者：Chelsea Finn ， Pieter Abbeel ， Sergey Levine 



### 解决的问题:

提出了一种与模型无关的元学习算法，该算法可与与梯度下降训练的任何模型兼容，并适用于各种不同的学习问题，包括分类，回归和强化学习。



针对各种学习任务训练一个模型，使得它只需要少量的训练样本就可以解决新的学习任务，

the agent must integrate its prior experience with a small amount of new information，while avoiding overfitting to the new data.

所以元学习的机制需要对于任务和完成任务所需要的计算形式都应该是general的



### idea：

算法的基本思想是训练模型的初始参数，不会扩展学习参数的数量也不会对模型架构施加约束，可与CNN，FCN，RNN结合，可微和不可微的loss都可以用。

从特征学习的角度来看，训练模型参数的过程可以将其视为构建广泛适用于多任务的内部表征。



MAML：直觉是某些内部表示形式比其他内部表示形式更具可移植性。

因此我们将以基于梯度的学习规则来学习模型，可以在从p（T）中提取的新任务上取得快速进展，而不会过度拟合。

目标是找到对任务的变化敏感的模型参数，即当沿p（T）的梯度方向改变参数时，参数的细微变化将极大改善从p（T）提取的任何任务的损失函数

### detail：



### 算法：

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512193929247.png" alt="image-20210512193929247" style="zoom:50%;" />

#### N-way K-shot：

N-way指训练数据中有N个类别，K-shot指每个类别下有K个被标记数据。

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512212907053.png" alt="image-20210512212907053" style="zoom:67%;" />



$f(\theta) $是参数为$\theta$的参数化的模型

meta-train classes: C1~C10，训练元模型![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D)，包含的共计300个样本，即 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+D%7D_%7Bmeta-train%7D) 

meta-test classes：P1~P5，精调（fine-tune）得到最终的模型 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bfine-tune%7D) ，共计100个样本，即 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+D%7D_%7Bmeta-test%7D) 



#### 根据5-way 5-shot的实验设置:

在训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 阶段：

* 从 ![[公式]](https://www.zhihu.com/equation?tex=C_1%EF%BD%9EC_%7B10%7D) 中随机取5个类别，每个类别再随机取20个已标注样本，组成一个**task** ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) 。  双随机：随机类别，随机样本，有点随机森林的意思，通过这种方式获得良好的泛化能力。
* 设置5个已标注样本称为 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) 的**support set**，另外15个样本称为 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) 的**query set**。 
* 这个**task** ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) ， 就相当于普通深度学习模型训练过程中的一条训练数据。那我们肯定要组成一个batch，才能做随机梯度下降SGD
* 所以我们反复在训练数据分布中抽取若干个这样的**task** ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) ，组成一个batch。
* 在训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bfine-tune%7D) 阶段，**task**、**support set**、**query set**的含义与训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 阶段均相同。



#### gradient by gradient：

第一种梯度更新：support set

可以理解为copy了一个原模型，计算出新的参数，用在第二轮梯度的计算过程中。

用了batch size个task对 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 进行了训练，然后我们使用上述batch个task中地**query set**去测试参数为![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Ctheta%7D%5E%7Bi%7D%2Ci%5Cin%5B1%2Cbatch+size%5D) 的 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 模型效果，获得总损失函数 ![[公式]](https://www.zhihu.com/equation?tex=L%28%5Cphi%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bbs%7D%7Bl%5E%7Bi%7D%28%5Chat%7B%5Ctheta%7D%5E%7Bi%7D%29%7D) ，这个损失函数就是一个**batch task**中**每个task**的**query set**在各自参数为 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Ctheta%7D%5E%7Bi%7D%2Ci%5Cin%5B1%2Cbatch+size%5D) 的 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 中的损失 ![[公式]](https://www.zhihu.com/equation?tex=l%5E%7Bi%7D%28%5Chat%7B%5Ctheta%7D%5E%7Bi%7D%29) 之和。

第二种梯度更新：query set，更新模型参数

即更新初始化参数 ![[公式]](https://www.zhihu.com/equation?tex=%5Cphi) ，也就是 ![[公式]](https://www.zhihu.com/equation?tex=%5Cphi%5CLeftarrow%5Cphi+-%5Ceta.%5Cpartial+L%28%5Cphi%29%2F%5Cpartial+%5Cphi) 来更新初始化参数。

对第一种里面batch size个task的loss融合后的loss的进行梯度下降，为了更好地泛化性，不对单一任务的loss更新模型参数，综合了多个task后再更新

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210513113344270.png" alt="image-20210513113344270" style="zoom:67%;" />









### 词句:

1、it is compatible with any model trained with gradient de- scent and applicable to a variety of different learning problems, including classification

它与任何用梯度下降法训练的模型兼容，适用于各种不同的学习问题，包括分类问题。

2、 In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task.

在我们的方法中，模型的参数被显式地训练，使得少量的梯度步长和少量的训练数据能够在新任务上产生良好的泛化性能。

3、As such, for the greatest applicability, the mechanism for learning to learn (or meta-learning) should be general to the task and the form of computation required to complete the task.        required to 

因此，为了最大化适用性，元学习的机制需要对于任务和完成任务所需要的都应该是general的

4、The key idea underlying our method is to train the model’s initial parameters such that the model has maximal perfor- mance on a new task after the parameters have been up- dated through one or more gradient steps computed with a small amount of data from that new task. 

我们方法的基本思想是训练模型的初始参数，以便在通过一个或多个梯度步骤更新参数后，该模型在新任务上具有最佳性能，而该梯度步骤是使用来自该新任务的少量数据计算出的

5、The process of training a model’s parameters can be viewed from a fea- ture learning standpoint as building an internal representa- tion that is broadly suitable for many tasks.

从特征学习的角度来看，训练模型参数的过程可以将其视为构建广泛适用于许多任务的内部表示。

6、with respect to 关于   The intuition behind this approach is  这种方法背后的直觉是







> 题目：Meta-Learning in Neural Networks: A Survey
>
> 作者：Timothy Hospedales, Antreas Antoniou, Paul Micaelli, Amos Storkey

### 解决的问题：

meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes.

元学习的目的是在经历多次学习的情况下，改进学习算法本身。

### detail：



#### 元学习：任务分配视角 

任务定义为数据集和loss函数T = {D,L}， 在任务分布p(T)上，评估w的性能，w指“如何学习”或“元知识”。L（D，w）是在数据集D上使用w衡量一个模型的性能

学习如何学习，因此成为：<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512111842070.png" alt="image-20210512111842070" style="zoom:50%;" />

meta-training stage：

we denote the set of M source tasks used in the meta-training stage as：<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512112606064.png" alt="image-20210512112606064" style="zoom:50%;" />  

其是从p(T)sample出来的子集（the source train and validation datasets are respectively called support and query sets.）

so，The meta-training step of ‘learning how to learn’ can be written as:<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512112818126.png" alt="image-20210512112818126" style="zoom:50%;" />

meta-testing stage：

we denote the set of Q target tasks used in the meta-testing stage as <img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512113357018.png" alt="image-20210512113357018" style="zoom:50%;" />

在元测试阶段，我们使用所学的元知识w 训练基本模型on each previously unseen target task i ：<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512113609003.png" alt="image-20210512113609003" style="zoom:50%;" />

#### 元学习：双层优化视角 

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512114542091.png" alt="image-20210512114542091" style="zoom:50%;" />

内层优化公式6是以外层定义的学习策略w为条件的，但在训练过程中不能改变w

#### 元学习：前馈模型视角（amortized）

有许多元学习方法，它们以前馈方式而不是通过显式迭代优化来综合模型，定义元训练线性回归的toy示例：

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210512115542070.png" alt="image-20210512115542070" style="zoom:50%;" />

训练集Dtr  is embedded  into a vector gw，gw定义为线性回归权重，以预测来自验证集的样本。

这一类方法，学习新任务的成本通过gw降低为前馈操作，迭代优化的时间用在了w元训练。

### 旧的分类：

元学习方法的分类：基于优化的方法、基于模型（或黑盒）的方法和基于度量（或非参数）的方法。

基于优化的方法：双层优化，如：MAML

基于模型的方法：前馈模型：该模型将当前数据集D嵌入到激活状态中，并根据该状态对测试数据进行预测。

外部优化和内部优化紧密耦合，因为w和D直接指定$ \theta$，缺点：泛化性能差且难以将大型训练集嵌入到模型中。

度量学习（Metric-Learning）： non-parametric algorithms

### 新的分类：

![image-20210512160254307](/Users/lishuo/Library/Application Support/typora-user-images/image-20210512160254307.png)



Meta-Representation：那些是可学习的元知识，那些是固定的。

应用：

在多任务场景中，任务不可知的知识是从一系列任务中提取出来的，并用于改进对该系列新任务的学习，

以及单个任务场景，其中单个问题被反复解决并在多个阶段得到改进



### 词句：

1、The previous discussion outlines the common flow of meta-learning in a multiple task scenario, but does not specify how to solve the meta-training step

前面的讨论概述了多任务场景中元学习的常见流程，但没有说明如何解决元训练步骤

2、the inner level optimization Eq. 6 is conditional on the learning strategy w defined by the outer level, but it cannot change w during its training.

内层优化公式6是以外层定义的学习策略w为条件的，但在训练过程中不能改变w

3、 because the cost of learning a new task is reduced to a feed-forward operation through gw, with iterative optimization already paid for during meta-training of w

因为学习一个新任务的成本通过gw降低为一个前馈操作，迭代优化的时间用在了w元训练。

4、elaborate alternatives





> 题目：Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation
>
> 来源： ICCV 2019
>
> 作者：Tongji University 、Huawei Noah’s Ark Lab
>
> 性能： 2.50% test set error rate on CIFAR-10.     top-1/5 errors of 24.4%/7.4%   on ImageNet

### 解决的问题

darts的不足：This is arguably due to the large gap between the architecture depths in search and evaluation scenarios.

浅层搜索，深层评估，制约是GPU内存。

### idea

<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210507171805993.png" alt="image-20210507171805993" style="zoom:67%;" />

增加深度带来计算量的剧增：search space approximation 

将搜索过程分为多个阶段，并在每个阶段结束时逐步增加网络深度，同时随着深度的增加，根据上一个搜索过程中的得分减少下一过程候选（操作）的数量。

增加深度带来不稳定：search space regularization

算法可能严重偏向于 skip-connect ，因为它往往导致优化过程中最快速的错误衰减，但实际上，更好的选择往往存在于可学习的操作，如卷积。

(i) introduces operation-level Dropout  to alleviate the dominance of skip-connect during training

* 每个stage开始， train the (modified) architecture from scratch，即所有架构参数重新初始化，because several candidates have been dropped .

* skip-layer开始阻塞，在其他路径充分学习后，再同等对待： introduces operation-level Dropout after each skip-connect operation to partially ‘cut off’ the straightforward path through skip-connect, and facilitate the algorithm to explore other operations.但是，如果我们不断地阻塞通过skip-connect的路径，算法会通过给它们分配较低的权值来丢弃它们，这对最终的性能是有害的。To address this contradiction, we gradually decay the Dropout rate during the training process in each search stage

(ii) controls the appearance of skip-connect during evaluation.

* If the number of skip-connects is not exactly M, we search for the M skip-connect operations with the largest architecture weights in this cell topology and set the weights of others to 0, then redo cell construction with modified architecture parameters.

### 改进

分阶段优化，逐步丢弃表现不佳的操作，随着训练操作减少，深度增加使得GPU内存要求不大。但是skip-layer的处理比较简单粗暴，能否也将其作为一个可以学东西的量，既然skip-layer可以单独拎出来是否还有其他可以单独拎出来的，拎出来和不拎出来也可以当做一个优化的目标。

那么结果就是，先固定skip-layer及其类似操作，优化architecture weight，再固定architecture weight，优化skip-layer及其类似操作。

### 词句：

1、Such gap hinders these approaches in their application to more complex visual recognition tasks

2、While a deeper architec- ture requires heavier computational overhead

3、 a better option often resides in learnable operations such as convolution

4、 alleviate the dominance of skip-connect 

5、the emerging field of neural archi- tecture search (NAS)

6、 which contradicts the common sense that deeper networks tend to perform better

7、with respect to

8、First, the computational overhead increases linearly with the depth    首先，计算开销随深度线性增加

9、 The search process is split into multiple stages  搜索过程分为多个阶段

10、 which makes our approach easy to be deployed on regular GPUs  这使得我们的方法很容易部署在常规gpu上

11、 the number of ...  varies from 2 to 4.  ...的数量从2-4不等



> 题目：PROXYLESSNAS: DIRECT NEURAL ARCHITECTURE SEARCH ON TARGET TASK AND HARDWARE
>
> 来源： ICLR 2019
>
> 作者：Han Cai, Ligeng Zhu, Song Han
>
> 性能： 2.08% test set error rate on CIFAR-10.    3.1% better top-1 accuracy  on ImageNet
>
> 结构：get rid of the meta-controller (or hypernetwork) by modeling NAS as a single training process of an over-parameterized network that comprises all candidate paths.
>
> ​		   通过将NAS建模为包含所有候选路径的超参数化网络的单个训练过程，从而摆脱了元控制器（或超网络）。

### 解决的问题：

1、DARTS可以通过连续表示网络体系结构来减少GPU的时间开销，但存在GPU内存消耗高的问题，提出了

2、DARTS在代理任务上训练，进而迁移到目标任务，无法保证在目标数据集是最优的。

3、DARTS为了实现迁移学习，这种方法只搜索几个架构cell，然后重复地堆叠相同的模式，这限制了block 的多样性，从而损害了性能。

### idea：

1、它直接学习目标任务和硬件上的体系结构，而不是使用代理

2、we also remove the restriction of repeating blocks in previous NAS works

3、memory consumption grows linearly w.r.t. the number of choices：binarize the architecture  parameters(1 or 1)。and force only one path to be active at run-time.    propose a gradient-based approach to train these binarized parameters based on BinaryConnect

![image-20210505204351613](/Users/lishuo/Library/Application Support/typora-user-images/image-20210505204351613.png)

network pruning :

相同点：improve the efficiency of neural networks by removing insignificant neurons or channels .

不同点：can not change the topology of the network，focus on layer-level pruning that only modifies the filter (or units) number of a layer 

### detail：

1、超参数化网络的构建同darts

2、We propose a gradient-based algorithm to train these binarized architecture parameters.如图：

![image-20210505213246443](/Users/lishuo/Library/Application Support/typora-user-images/image-20210505213246443.png)

3、

![image-20210506111632852](/Users/lishuo/Library/Application Support/typora-user-images/image-20210506111632852.png)

在运行时内存中只有一条激活路径处于活动状态，因此训练超参数网络的内存需求降低到了训练紧凑模型的相同级别。

4、将从N候选路径选择一条转化成多个二选一的任务：直觉是若某条路径在所有候选路径最优，那么该路径和其他路径两两比较也是最最优的。

### 改进：

直觉是若某条路径在所有候选路径最优，那么该路径和其他路径两两比较也是最最优的

问题：最优的路径一开始可能不是表现最优秀的甚至可能比较差，还没等他发挥潜力就被优化掉了。



### 词句：

1、To address this issue, we consider factorizing the task of choosing one path out of N candidates into multiple binary selection tasks.

2、The intuition is that if a path is the best choice at a particular position, it should be the better choice when solely compared to any other path

3、 Finally, as path weights are computed by applying softmax to the architecture parameters, we need to rescale the value of these two updated architecture parameters by multiplying a ratio to keep the path weights of unsampled paths unchanged.

4、in each update step, one of the sampled paths is enhanced (path weight increases) and the other sampled path is attenuated (path weight decreases) while all other paths keep unchanged. 



> 题目：SNAS: STOCHASTIC NEURAL ARCHITECTURE SEARCH
>
> 来源： ICLR 2019
>
> 作者：Sirui Xie, Hehui Zheng, Chunxiao Liu, Liang Lin
>
> 性能： 2.85±0.02%  test set error rate on CIFAR-10.    



### 解决的问题：

* 和ENAS相比，SNAS的搜索优化可微分，搜索效率更高，可以在更少的迭代次数下收敛到更高准确率。

* 与其他可微分的方法（DARTS）相比，SNAS直接优化NAS任务的目标函数，搜索结果偏差更小，可以直接通过一阶优化搜索。

- 此外，基于SNAS保持了概率建模的优势，作者提出同时优化网络损失函数的期望和网络正向时延的期望，扩大了有效的搜索空间，可以自动生成硬件友好的稀疏网络。

### idea：

NAS是一个确定环境中的完全延迟奖励的任务：

即ENAS只有在网络结构最终确定后，agent才能获得一个非零得分acc，而在一个网络被完全搭建好并训练及测试之前，agent的每一个动作都不能获得直接的得分奖励。agent只会在整一条动作序列（trajectory）结束之后，获得一个得分。

TD Learning与贡献分配：

强化学习的目标函数，是将来得分总和的期望。从每一个状态中动作的角度来说，agent应该尽量选择长期来说带来最大收益的动作。然而，如果没有辅助的预测机制，agent并不能在每一个状态预测每一个动作将来总得分的期望。TD Learning就是用来解决这个问题，预测每一个动作对将来总得分的贡献的。（1）这种动态规划的局部信息传递带来的风险就是，当将来某些状态的价值评估出现偏差时，它过去的状态的价值评估也会出现问题。而这个偏差只能通过更多次的动态规划来修复。



用损失函数（使输出与每个输入直接相关）替代准确率，就可以使NAS问题可微。具体来说，本文继承了DARTS的思想，但是并不是直接训练所有操作的权值，而是通过决策$Z$对子网络进行采样，并根据所有子网络的表现构建损失函数。具体来说，从母网络中产生子网络，可以通过在母网络的每一条边的所有可能神经变换的结果后乘上一个one-hot向量来实现。而对于子网络的采样，就因此自然转化为了对一系列one-hot随机变量的采样（包含0操作，即不连接这条边）。
<img src="/Users/lishuo/Library/Application Support/typora-user-images/image-20210511160131527.png" alt="image-20210511160131527" style="zoom:67%;" />

### motivations：



One of the key motivations of SNAS is to replace the feedback mechanism triggered by constant rewards in reinforcement-learning-based NAS with more efficient gradient feedback from generic loss

SNAS的一个重要动机是用更有效的梯度反馈代替基于强化学习的NAS中由恒定奖励触发的反馈机制









### 词句：

1、NAS pipeline comprises architecture sampling, parameter learning, architecture validation, credit assignment and search direction update.

2、Due to the pervasive non-linearity in neural operations, it introduces untractable bias to the loss function.

3、 is reformulated as 

4、but assigns credits to structural de- cisions more efficiently. This credit assignment is further augmented with locally decomposable reward to enforce a resource-efficient constraint

5、pervasive

