首发于[自动驾驶论文速递](https://www.zhihu.com/column/c_1145268367400280064)

# 从检测到人脸检测

[![言煜秋](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgv2-fbb66a4ba07a08732d3cf8b417569f22_xs-20211222215542095.jpg)](https://www.zhihu.com/people/waitsop)

[言煜秋](https://www.zhihu.com/people/waitsop)

## 说点废话

最近把目前（2019.11之前）从普通各类物体检测到人脸检测的算法都大概看了看，本文先介绍检测部分，人脸检测会再写一篇。

Detection的发展是一段漫长的历史，值得一提的是分别为两个不同阵营（two-stage和one-stage）的大作，**Fast RCNN和YOLO**和紧随以后的**Faster RCNN和SSD**都是15年诞生的。



![img](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgv2-99e7eb62762e0706b43edf882a9f7da6_720w.jpg)检测算法概述

先从之前做的笔记搬张detection的综述，图中的算法都看了一遍，理解的有深有浅。本文不详细介绍每个算法，而是尽量用最少的话概括创新点的核心思想，又想了想既然是归纳文章拖得太长自己都看不下去，所以图也不放了。

PS:想真正搞懂一个篇文章，“易于吸收”的博客固然是快速了解的好方法，但paper和code也一定要看。paper的重要性不用多说，而想要深入到算法的每个细节，看代码是必经之路（理论和代码的实现经常是不同的）。

先把我准备介绍的检测，人脸检测算法列一下（欢迎指正和补充）：

## 检测  D**etection**

- [RCNN](onenote:#RCNN&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={564FD99A-FFC7-481A-A451-CAD653F04377}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Fast RCNN](onenote:#Fast RCNN&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={222D815B-BA16-4C7C-B916-049AA5AA5E9B}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Faster RCNN](onenote:#Faster RCNN&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={A2550DF0-52AA-491B-842D-C9E3D5C64796}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [R-FCN](onenote:#R-FCN&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={BBD4F745-C1ED-43DA-8E55-0ADD4A8B0D0B}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Mask RCNN](onenote:#Mask RCNN&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={E908A374-3575-4EDC-A495-5364D2AD857D}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one)
- [SPP](onenote:#SPP&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={DE06F6D6-D4F4-49AB-87DB-BE821F445060}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [FPN](onenote:#FPN&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={B3BD735A-CCA7-4C80-9206-99E64D9CFA3B}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [SNIP](onenote:#SNIP&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={852581D1-002E-4834-AABC-74264C1B8524}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [SNIPER](onenote:#SNIPER&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={B61BCB91-E2F1-42E0-82D3-58FA637922DD}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Trident](onenote:#Trident&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={49BE036F-B047-43DB-8E77-70B296FF1F73}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one)
- [Multibox](onenote:#Multibox(CVPR2014)&section-id={A356003D-5E6A-4EE4-BE40-66902E55F518}&page-id={CEBBCB69-63BD-45E7-9779-55114A1AF73D}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/检测算法/算法/检测.one) [YOLO](onenote:#YOLO&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={8C040686-DAEA-4AFF-BDB6-1BD480BCF879}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [DenseBox](onenote:#DenseBox&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={3E1F6EDA-5B79-415B-9593-AA305B332F1D}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [SSD ](onenote:#SSD&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={8B5432F9-DEC7-46F9-BEB6-EA3FD85D5EC8}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [YOLOv2 ](onenote:#YOLOv2&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={99E45558-B77F-4DCE-82DA-CD256C926A2C}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Retina](onenote:#Retina&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={6FE79329-5801-42B6-9840-F0BDFAFF2BFE}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [YOLOv3](onenote:#YOLOv3&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={F30844C7-0596-4934-9BB6-28007FFD1953}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [CornerNet ](onenote:#CornerNet&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={A4AB02B5-9014-4085-AD30-4A25DFD7E354}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [CenterNet ](onenote:#CenterNet&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={B0B17265-2819-4A80-AB63-238C7E86EAA5}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [AlignDet](onenote:#AlignDet&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={45F36CFF-4F29-4900-B075-8FB46AB5614B}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [GA-RetinaNet ](onenote:#GA-RetinaNet&section-id={A356003D-5E6A-4EE4-BE40-66902E55F518}&page-id={99726FF7-C836-4175-BB63-22FFA27D7F81}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/检测算法/算法/检测.one) [Dubox ](onenote:#Dubox&section-id={A356003D-5E6A-4EE4-BE40-66902E55F518}&page-id={2FA2CF83-A22D-4E4D-8795-4F5A2C6288F5}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/检测算法/算法/检测.one) [GIOU](onenote:检测.one#GIOU（CVPR2019）&section-id={A356003D-5E6A-4EE4-BE40-66902E55F518}&page-id={3AD1A7C3-F4B7-44F2-9C38-67EC6B0F42FE}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/检测算法/算法)
- [NonLocal](onenote:#NonLocal&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={EC56B488-C254-4A83-80C8-E1F6754D876D}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [RelationNet](onenote:#RelationNet&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={E18C81D1-4072-4415-B473-8BDFDDD3C3AB}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Cascade](onenote:#Cascade&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={B1479C07-4869-4559-867F-5434295D9FF0}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [IOU-Net](onenote:#IOU-Net&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={E9F023A8-462F-4B68-82D9-D06F5EE61586}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [Scoring ](onenote:#Scoring&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={C5CD442C-9A24-4120-946C-91438D1834FB}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one)
- [DCNv1](onenote:#DCNv1&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={0CEE9BFC-76BB-4E15-9249-E3FC4C2349A8}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [DCNv2](onenote:#DCNv2&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={3BC2C5CB-B712-486C-9B67-839660994711}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) [RepPoint](onenote:#RepPoint&section-id={2CF68AA5-609C-4ABD-B8C6-DFC6C960EAB0}&page-id={6F65F790-5151-4D5D-8783-A16319EB652C}&end&base-path=https://d.docs.live.net/197fb635d23fe972/文档/ten/mrcnn_code/算法/检测.one) 

------

## **R-CNN（ECCV2014）**

**用Selective Search算法从原图提取 2000 个类别独立的候选区域（region proposal），分别过CNN → SVM分类 + 回归（对每一类都训练一个线性回归器）**

**Fast RCNN (ICCV2015)**

SPP Net检测流程相对于RCNN：

结合空间金字塔方法实现CNNs的多尺度输入。

只对原图提取一次卷积特征

Fast R-CNN = R-CNN + SPP Net

Fast RCNN 相比 RCNN：

**只提一次特征（讲提取特征部分称为共享卷积层）  原图先过CNN提特征，在feature map上得到每个候选框特征（候选框仍然用Selective Search生成，只不过映射到了特征图上）→ 分类+回归**

最后一个卷积层后加 ROI pooling layer

## **Faster RCNN(NIPS2015)**

用RPN（region proposal network）替代selective search，同时引入anchor box应对目标形状变化。
**原图 → 共享卷积层得到特征图 → RPN网络得到候选框→ ROI pooling（将不同大小候选框归一） → 分类+回归**
（RPN网络内部包含classification+boundingbox  regression两个分支，此过程涉及到anchor等重要概念，要深入理解，详细的介绍网上有很多，这里提几个重要的点：1.anchor不是真实存在的  2.最大的anchor超过了特征图对应处在原图上的感受野，但论文中作者表示不需要全部信息同样可以大概预估框的位置，如人看到一半脸会预测整张脸的位置，但这种预测毕竟较正常情况不准一些，后续的算法中往往让anchor在感受野内）

## **R-FCN（Region based Fully Convolutional Network）**

前文中之所以需要ROI pooling是因为全连接层的存在，因为分类任务中stage of the  art的往往是全卷积网络，作者想能不能用全卷积做检测任务，但发现简单替换效果很差，于是加了一个关键层：位置敏感ROI池化层（position-sensitive RoI pooling layer）

**原图 → 共享卷积层 → RPN+继续卷积两个分支 → 位置敏感ROI池化层 → vote**

（把ROI分成九宫格，投票+softmax得到最终得分，核心思想是把分类和位置信息融合在一起了）

## Mask R-CNN

相比Faster R-CCN，提特征时引入了FCN（多尺度的通用结构），过了RPN后增加了一个全卷积的分支用来像素级分割（原来是只有分类+回归两个分支）。此算法有太多的东西在code里而论文中没说的，分割任务的经典算法，即使到现在也不过时，很值得学习。

------

## SPP

输入图像总要适应网络（因为全连接层的存在）而改变横纵比导致效果不好。

SPP：大小不一的图片进入网络，在最后一层卷积层后，把feature map分成如4x4，再展开就成了16长度的向量，同样2x2，1x1也可以同时进行然后拼在一起，最后输入到全连接层。

## FPN

先下采样再上采样再连接，下采样是用如ResNets的backbone，上采样用最邻近上采样（这样就把抽象，语义强的高层特征图和高分辨率的底层特征图结合起来了），值得注意的是把上下采样中的每一个相同尺度的层连接了起来（前面的→1x1+后面的），最后输出是几层一起输入到下一部分的。

**SNIP**

**明天再写，大家有什么建议欢迎提出，后面写时会改进的！**

参考：

[打个酱油：我这两年的目标检测1624 赞同 · 54 评论文章![img](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgv2-ec6843f20272592b572156762fed4efd_180x120.jpg)](https://zhuanlan.zhihu.com/p/82491218)



编辑于 2020-08-10 14:43

[目标检测](https://www.zhihu.com/topic/19596960)

[计算机视觉](https://www.zhihu.com/topic/19590195)

[人脸识别](https://www.zhihu.com/topic/19559196)

### 文章被以下专栏收录

- [![自动驾驶论文速递](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/img4b70deef7_xs.jpg)](https://www.zhihu.com/column/c_1145268367400280064)

- ## [自动驾驶论文速递](https://www.zhihu.com/column/c_1145268367400280064)

- 自动驾驶工程师的晨间拿铁，一天一篇，喝了在上。

- [![AI on chip](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgv2-4092259e0fc66d3a7d2fc134848cf24e_xs-20211222215542219.jpg)](https://www.zhihu.com/column/c_1178097838814363648)

- ## [AI on chip](https://www.zhihu.com/column/c_1178097838814363648)

- 深度学习算法部署嵌入端

### 推荐阅读



[目标检测: DSSD (人脸检测问题)DSSD : Deconvolutional Single Shot Detector 这次介绍一下这篇文章, DSSD. 了解SSD的应该都知道这篇的共同一作就是SSD的作者, 这说明文章定位之初就是改进SSD. 因为这一系列的文章都是讨…Mr hour](https://zhuanlan.zhihu.com/p/44589434)[![人脸检测： FaceBoxes](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgv2-e80f71bdf05a3fa050d34f3a5041dad3_250x0.jpg)人脸检测： FaceBoxes六年发表于深度学习论...](https://zhuanlan.zhihu.com/p/58705459)[![人脸检测之DSFD详解](https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgv2-33ff482aca8fbb34f38fd9ab245ad1a9_250x0.jpg)人脸检测之DSFD详解dengd...发表于CV视界](https://zhuanlan.zhihu.com/p/67690568)[《目标检测》-第13章-人脸检测实战-YOLAF呀吼！ 好久不见！ 这次的主要是想做点 人脸检测（face detection）的实战demo，我们就叫它—— You Only Look At Face，YOLAF。由于我的目标是希望设计一个轻量化的人脸检测模型，所以命名…Kissr...发表于目标检测入...](https://zhuanlan.zhihu.com/p/145868300)

## 还没有评论

评论区功能升级中