<img src="https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgimage-20211220161317974.png" alt="image-20211220161317974" style="zoom:50%;" />



 Bagging是**B**ootstrap **agg**regat**ing**的缩写，代表：随机森林

**是什么：**

自助采样法是一种可重复采样方法

• 从给定的数据集中通过有放回式抽样，产生一个或多个不同新数据集的方法;

• 给定包含*m*个样本的数据集 ，对其采样产生数据集*D* :

<img src="https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgimage-20211220162134254.png" alt="image-20211220162134254" style="zoom:33%;" />

**基本流程:**

– 采样出T个含m个训练样本的采样集;

– 基于每个采样集训练一个基学习器;

– 通过简单投票法(平均法)将这些基学习器进行结合;

**特点：**

Bagging要求基学习器具有“不稳定”性，即:数据集上小的扰动能够使分类结果产生显著变动;

**Random Forest随机森林：**



**是什么：**

* 以决策树为基学习器构建
* 被誉为“代表集成学习技术水平的方法” 
* Bagging算法的一个扩展变体
* 双扰动

​    

**“样本集扰动”+“属性集扰动” 双随 机  ：**

传统决策树 ：在选择划分属性时在当前节点的属性集合中选择一个最优性

随机森林：对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含**k**个属性的子集，然后后从该子集中选择一个最优属性用划分。

##### code：



```

```



### AdaBoost



**基本流程** 

– 先从初始训练集训练出一个基学习器;

– 再根据基学习器的表现对训练样本分布进行调整，使 得先前基学习器做错的训练样本在后续收到更多关注

 – 然后基于调整后的样本分布来训练下一个基学习器 – 重复M轮得到M个基学习器，将其加权结合。

<img src="https://xiaoguciu.oss-cn-beijing.aliyuncs.com/imgimage-20211220201024527.png" alt="image-20211220201024527" style="zoom:50%;" />



